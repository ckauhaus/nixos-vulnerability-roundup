# Vulnerability roundup 107: spark-2.4.8: 5 advisories [9.1]

[search](https://search.nix.gsc.io/?q=spark&i=fosho&repos=NixOS-nixpkgs), [files](https://github.com/NixOS/nixpkgs/search?utf8=%E2%9C%93&q=spark+in%3Apath&type=Code)

* [ ] [CVE-2019-20445](https://nvd.nist.gov/vuln/detail/CVE-2019-20445) CVSSv3=9.1 (nixos-unstable)
* [ ] [CVE-2016-9177](https://nvd.nist.gov/vuln/detail/CVE-2016-9177) CVSSv3=7.5 (nixos-unstable)
* [ ] [CVE-2018-11804](https://nvd.nist.gov/vuln/detail/CVE-2018-11804) CVSSv3=7.5 (nixos-unstable)
* [ ] [CVE-2018-9159](https://nvd.nist.gov/vuln/detail/CVE-2018-9159) CVSSv3=5.3 (nixos-unstable)
* [ ] [CVE-2018-11770](https://nvd.nist.gov/vuln/detail/CVE-2018-11770) CVSSv3=4.2 (nixos-unstable)

## CVE details

### CVE-2019-20445

HttpObjectDecoder.java in Netty before 4.1.44 allows a Content-Length header to be accompanied by a second Content-Length header, or by a Transfer-Encoding header.

### CVE-2016-9177

Directory traversal vulnerability in Spark 2.5 allows remote attackers to read arbitrary files via a .. (dot dot) in the URI.

### CVE-2018-11804

Spark's Apache Maven-based build includes a convenience script, 'build/mvn', that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.

### CVE-2018-9159

In Spark before 2.7.2, a remote attacker can read unintended static files via various representations of absolute or relative pathnames, as demonstrated by file: URLs and directory traversal sequences. NOTE: this product is unrelated to Ignite Realtime Spark.

### CVE-2018-11770

From version 1.3.0 onward, Apache Spark's standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property 'spark.authenticate.secret' establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting 'spark.authenticate.secret' when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of 'spark.master.rest.enabled' to 'false'.

-----
Scanned versions: nixos-unstable: 34ad3ffe08a.

Cc @illustris
Cc @kamilchm
Cc @offlinehacker
Cc @thoughtpolice

